{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import configparser\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql.functions import expr, udf, col, lit, year, month, upper, to_date, monotonically_increasing_id, when, substring\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from pyspark.sql.functions import date_add as d_add \n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:3.0.0-s_2.12\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "    return spark\n",
    "\n",
    "def rename_columns(table, new_columns):\n",
    "    for original, new in zip(table.columns, new_columns):\n",
    "        table = table.withColumnRenamed(original, new)\n",
    "    return table\n",
    "\n",
    "# DB Properties\n",
    "db_properties={}\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"parameters.cfg\")\n",
    "db_prop = config['postgresql']\n",
    "db_url = db_prop['url']\n",
    "db_user = db_prop['username']\n",
    "db_password = db_prop['password']\n",
    "db_properties['username']=db_prop['username']\n",
    "db_properties['password']=db_prop['password']\n",
    "db_properties['url']=db_prop['url']\n",
    "db_properties['driver']=db_prop['driver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_immigration_data(input_path):\n",
    "    # Read in the data here\n",
    "    sas_files = os.listdir(f\"{input_path}sas/\")\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    def customUnion(df1, df2):\n",
    "        cols1 = df1.columns\n",
    "        cols2 = df2.columns\n",
    "        total_cols = sorted(cols1 + list(set(cols2) - set(cols1)))\n",
    "        def expr(mycols, allcols):\n",
    "            def processCols(colname):\n",
    "                if colname in mycols:\n",
    "                    return colname\n",
    "                else:\n",
    "                    return lit(None).alias(colname)\n",
    "            cols = map(processCols, allcols)\n",
    "            return list(cols)\n",
    "        appended = df1.select(expr(cols1, total_cols)).union(df2.select(expr(cols2, total_cols)))\n",
    "        return appended\n",
    "\n",
    "    i = 0\n",
    "    for file in sas_files:\n",
    "        if i == 0:\n",
    "            df_spark = spark\\\n",
    "                    .read\\\n",
    "                    .format('com.github.saurfang.sas.spark')\\\n",
    "                    .load(f\"{input_path}sas/{file}\")\n",
    "            df_final = df_spark\n",
    "        else:\n",
    "            df_spark = spark\\\n",
    "                    .read\\\n",
    "                    .format('com.github.saurfang.sas.spark')\\\n",
    "                    .load(f\"{input_path}sas/{file}\")\n",
    "            df_final = customUnion(df_final,df_spark)\n",
    "        i += 1\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_immigration_table(df, table):\n",
    "    \"\"\" \n",
    "        Description: create the fact immigration table\n",
    "        Arguments:\n",
    "            df: dataframe generated by Spark\n",
    "            table: table name\n",
    "            output_path: Target directory\n",
    "        Return:\n",
    "            df: dataframe generated by Spark\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Start creating states table\")\n",
    "\n",
    "    sas_epoch = datetime.datetime(1960, 1, 1)\n",
    "\n",
    "    df_immigration = df \\\n",
    "            .withColumn(\"immigration_id\", monotonically_increasing_id()) \\\n",
    "            .withColumn(\"cic_id\", col(\"cicid\").cast(\"integer\")) \\\n",
    "            .drop(\"cicid\") \\\n",
    "            .withColumnRenamed(\"i94addr\", \"cod_state\") \\\n",
    "            .withColumnRenamed(\"i94port\", \"cod_port\") \\\n",
    "            .withColumn(\"cod_visa\", col(\"i94visa\").cast(\"integer\")) \\\n",
    "            .drop(\"i94visa\") \\\n",
    "            .withColumn(\"cod_mode\", col(\"i94mode\").cast(\"integer\")) \\\n",
    "            .drop(\"i94mode\") \\\n",
    "            .withColumn(\"cod_country_origin\", col(\"i94res\").cast(\"integer\")) \\\n",
    "            .drop(\"i94res\") \\\n",
    "            .withColumn(\"cod_country_cit\", col(\"i94cit\").cast(\"integer\")) \\\n",
    "            .drop(\"i94cit\") \\\n",
    "            .withColumn(\"year\", col(\"i94yr\").cast(\"integer\")) \\\n",
    "            .drop(\"i94yr\") \\\n",
    "            .withColumn(\"month\", col(\"i94mon\").cast(\"integer\")) \\\n",
    "            .drop(\"i94mon\") \\\n",
    "            .withColumn(\"bird_year\", col(\"biryear\").cast(\"integer\")) \\\n",
    "            .drop(\"biryear\") \\\n",
    "            .withColumn(\"age\", col(\"i94bir\").cast(\"integer\")) \\\n",
    "            .drop(\"i94bir\") \\\n",
    "            .withColumn(\"counter\", col(\"count\").cast(\"integer\")) \\\n",
    "            .drop(\"count\") \\\n",
    "            .withColumn(\"arrival_date\", to_date(lit(\"arrdate\"))) \\\n",
    "            .withColumn(\"departure_date\", to_date(lit(\"depdate\"))) \\\n",
    "            .drop(\"arrdate\", \"depdate\")\n",
    "\n",
    "    df_immigration.printSchema()\n",
    "\n",
    "    df_immigration.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url) \\\n",
    "        .option(\"dbtable\", table) \\\n",
    "        .option(\"user\", db_user) \\\n",
    "        .option(\"password\", db_password) \\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airlines_table(input_path, table):\n",
    "\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    df_raw = spark.\\\n",
    "        read\\\n",
    "        .format(\"csv\")\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "        .option(\"delimiter\", \",\")\\\n",
    "        .load(input_path + \"airlines.csv\")\n",
    "\n",
    "    df_airlines = df_raw.\\\n",
    "            select(\"*\")\\\n",
    "            .withColumn(\"airline_id\", df_raw[0]) \\\n",
    "            .withColumn(\"airline_name\", df_raw[1]) \\\n",
    "            .withColumn(\"alias\", df_raw[2]) \\\n",
    "            .withColumn(\"iata\", df_raw[3]) \\\n",
    "            .withColumn(\"ica0\", df_raw[4]) \\\n",
    "            .withColumn(\"callsign\", df_raw[5]) \\\n",
    "            .withColumn(\"country\", df_raw[6]) \\\n",
    "            .withColumn(\"active\", df_raw[7]) \\\n",
    "            .drop(\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\", \"_c7\")\n",
    "\n",
    "    df_airlines.printSchema()\n",
    "\n",
    "    df_airlines = df_airlines\\\n",
    "            .select(\"airline_id\", \"airline_name\", \"alias\", \"iata\", \"ica0\", \"callsign\", \"country\", \"active\")\\\n",
    "            .withColumn(\"alias\", when(df_airlines[\"alias\"] == \"\\\\N\", None).otherwise(df_airlines[\"alias\"]))\\\n",
    "            .write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", db_url) \\\n",
    "            .option(\"dbtable\", table) \\\n",
    "            .option(\"user\", db_user) \\\n",
    "            .option(\"password\", db_password) \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airports_table(input_path, table):\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    df_raw = spark.\\\n",
    "        read\\\n",
    "        .format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"delimiter\", \";\")\\\n",
    "        .load(input_path + \"airport-codes_csv.csv\")\n",
    "\n",
    "    df_airports = df_raw.\\\n",
    "            select(\"*\")\\\n",
    "            .where(\n",
    "                (col(\"iso_country\") == \"US\")\n",
    "                & (col(\"type\").isin(\"large_airport\", \"medium_airport\", \"small_airport\"))\n",
    "                ) \\\n",
    "            .withColumn(\"iso_region\", substring(col(\"iso_region\"), 4, 2)) \\\n",
    "            .withColumn(\"elevation_ft\", col(\"elevation_ft\").cast(\"float\"))\n",
    "    \n",
    "    df_airports.printSchema()\n",
    "\n",
    "    df_airports \\\n",
    "            .write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", db_url) \\\n",
    "            .option(\"dbtable\", table) \\\n",
    "            .option(\"user\", db_user) \\\n",
    "            .option(\"password\", db_password) \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographics_table(input_path, table):\n",
    "\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    df_raw = spark.\\\n",
    "        read\\\n",
    "        .format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"delimiter\", \";\")\\\n",
    "        .load(input_path + \"us-cities-demographics.csv\")\n",
    "\n",
    "    df_demographics = df_raw.\\\n",
    "            select(\"*\")\\\n",
    "            .groupBy(col(\"City\"), col(\"State\"), col(\"Median Age\"), col(\"Male Population\"),\n",
    "                                        col(\"Female Population\") \\\n",
    "                                        , col(\"Total Population\"), col(\"Number of Veterans\"), col(\"Foreign-born\"),\n",
    "                                        col(\"Average Household Size\") \\\n",
    "                                        , col(\"State Code\")).pivot(\"Race\").agg(_sum(\"count\").cast(\"integer\")) \\\n",
    "            .fillna({\"American Indian and Alaska Native\": 0,\n",
    "                        \"Asian\": 0,\n",
    "                        \"Black or African-American\": 0,\n",
    "                        \"Hispanic or Latino\": 0,\n",
    "                        \"White\": 0})\n",
    "    \n",
    "    df_demographics.printSchema()\n",
    "\n",
    "    df_demographics \\\n",
    "            .write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", db_url) \\\n",
    "            .option(\"dbtable\", table) \\\n",
    "            .option(\"user\", db_user) \\\n",
    "            .option(\"password\", db_password) \\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label_descriptions(input_path):\n",
    "    \"\"\" Parsing label desctiption file to get codes of country, city, state\n",
    "        Arguments:\n",
    "            input_path {object}: Source S3 endpoint\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    spark = create_spark_session()\n",
    "\n",
    "    logging.info(\"Start processing label descriptions\")\n",
    "    label_file = os.path.join(input_path + \"I94_SAS_Labels_Descriptions.SAS\")\n",
    "    with open(label_file) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    print(\"    Creating country table\")\n",
    "    country_code = {}\n",
    "    for countries in contents[10:298]:\n",
    "        pair = countries.split('=')\n",
    "        code, country = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "        country_code[code] = country\n",
    "    df_countries = spark.createDataFrame(country_code.items(), ['code', 'country'])\n",
    "    df_countries \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url) \\\n",
    "        .option(\"dbtable\", \"countries\") \\\n",
    "        .option(\"user\", db_user) \\\n",
    "        .option(\"password\", db_password) \\\n",
    "        .save()\n",
    "\n",
    "    df_countries.printSchema()\n",
    "\n",
    "    print(\"    Creating city table\")\n",
    "    city_code = {}\n",
    "    for cities in contents[303:962]:\n",
    "        pair = cities.split('=')\n",
    "        code, city = pair[0].strip(\"\\t\").strip().strip(\"'\"),\\\n",
    "                     pair[1].strip('\\t').strip().strip(\"''\")\n",
    "        city_code[code] = city\n",
    "    df_cities = spark.createDataFrame(city_code.items(), ['code', 'city'])\n",
    "    df_cities \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url) \\\n",
    "        .option(\"dbtable\", \"cities\") \\\n",
    "        .option(\"user\", db_user) \\\n",
    "        .option(\"password\", db_password) \\\n",
    "        .save()\n",
    "\n",
    "    df_cities.printSchema()\n",
    "\n",
    "    print(\"    Creating state table\")\n",
    "    state_code = {}\n",
    "    for states in contents[982:1036]:\n",
    "        pair = states.split('=')\n",
    "        code, state = pair[0].strip('\\t').strip(\"'\"), pair[1].strip().strip(\"'\")\n",
    "        state_code[code] = state\n",
    "    df_states = spark.createDataFrame(state_code.items(), ['code', 'state'])\n",
    "    df_states \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url) \\\n",
    "        .option(\"dbtable\", \"states\") \\\n",
    "        .option(\"user\", db_user) \\\n",
    "        .option(\"password\", db_password) \\\n",
    "        .save()\n",
    "\n",
    "    df_states.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading immigration data...\n",
      "Creating immigration table...\n",
      "root\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- delete_days: double (nullable = true)\n",
      " |-- delete_dup: double (nullable = true)\n",
      " |-- delete_mexl: double (nullable = true)\n",
      " |-- delete_recdup: double (nullable = true)\n",
      " |-- delete_visa: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- cod_state: string (nullable = true)\n",
      " |-- cod_port: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- validres: double (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- immigration_id: long (nullable = false)\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- cod_visa: integer (nullable = true)\n",
      " |-- cod_mode: integer (nullable = true)\n",
      " |-- cod_country_origin: integer (nullable = true)\n",
      " |-- cod_country_cit: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- bird_year: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- counter: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      "\n",
      "Creating airlines table...\n",
      "root\n",
      " |-- airline_id: string (nullable = true)\n",
      " |-- airline_name: string (nullable = true)\n",
      " |-- alias: string (nullable = true)\n",
      " |-- iata: string (nullable = true)\n",
      " |-- ica0: string (nullable = true)\n",
      " |-- callsign: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- active: string (nullable = true)\n",
      "\n",
      "Creating airports table...\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: float (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "Creating tables from SAS desciption file...\n",
      "    Creating country table\n",
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "    Creating city table\n",
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "    Creating state table\n",
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "Process finished\n"
     ]
    }
   ],
   "source": [
    "input_path = \"D:/Temp/Data/\"\n",
    "output_path = \"D:/Temp/Results/\"\n",
    "\n",
    "print(\"Reading immigration data...\")\n",
    "cachedDF = read_immigration_data(input_path)\n",
    "print(\"Creating immigration table...\")\n",
    "create_immigration_table(cachedDF, \"immigration\")\n",
    "cachedDF.unpersist()\n",
    "print(\"Creating airlines table...\")\n",
    "create_airlines_table(input_path, \"airlines\")\n",
    "print(\"Creating airports table...\")\n",
    "create_airports_table(input_path, \"airports\")\n",
    "print(\"Creating tables from SAS desciption file...\")\n",
    "process_label_descriptions(input_path)\n",
    "print(\"Process finished\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e254ffc773357790aa04a01fb60c7c6721ec5a0c6f1763bcb2e925b3d380624c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
